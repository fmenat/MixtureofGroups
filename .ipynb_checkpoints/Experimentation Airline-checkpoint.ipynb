{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import keras, time, sys, os, gc\n",
    "\n",
    "DTYPE_OP = 'float32'\n",
    "keras.backend.set_floatx(DTYPE_OP)\n",
    "\n",
    "if DTYPE_OP == 'float64':\n",
    "    keras.backend.set_epsilon(np.finfo(np.float64).eps)\n",
    "elif DTYPE_OP == 'float32':\n",
    "    keras.backend.set_epsilon(np.finfo(np.float32).eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GLOBAL Variables\n",
    "BATCH_SIZE = 128 \n",
    "EPOCHS_BASE = 50 #or 100\n",
    "OPT = 'adam' #optimizer for neural network \n",
    "TOL = 3e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"./AirlineSentiment/\"\n",
    "label_names = [\"negative\",\"neutral\",\"positive\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data and preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num. train texts: 14680\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "FLAGS = re.MULTILINE | re.DOTALL\n",
    "def allcaps(text):\n",
    "    text = text.group()\n",
    "    return text.lower() + \" <allcaps>\"\n",
    "def tokenize(text):\n",
    "    # Different regex parts for smiley faces\n",
    "    eyes = r\"[8:=;]\"\n",
    "    nose = r\"['`\\-]?\"\n",
    "    def re_sub(pattern, repl):\n",
    "        return re.sub(pattern, repl, text, flags=FLAGS)\n",
    "\n",
    "    text = re_sub(r\"https?:\\/\\/\\S+\\b|www\\.(\\w+\\.)+\\S*\", \"<url>\")\n",
    "    text = re_sub(r\"/\",\" / \")\n",
    "    text = re_sub(r\"@\\w+\", \"<user>\")\n",
    "    text = re_sub(r\"{}{}[)dD]+|[)dD]+{}{}\".format(eyes, nose, nose, eyes), \"<smile>\")\n",
    "    text = re_sub(r\"{}{}p+\".format(eyes, nose), \"<lolface>\")\n",
    "    text = re_sub(r\"{}{}\\(+|\\)+{}{}\".format(eyes, nose, nose, eyes), \"<sadface>\")\n",
    "    text = re_sub(r\"{}{}[\\/|l*]\".format(eyes, nose), \"<neutralface>\")\n",
    "    text = re_sub(r\"<3\",\"<heart>\")\n",
    "    text = re_sub(r\"[-+]?[.\\d]*[\\d]+[:,.\\d]*\", \"<number>\")\n",
    "    text = re_sub(r\"#\\S+\", \"<hashtag>\")\n",
    "    text = re_sub(r\"([!?.]){2,}\", r\"\\1 <repeat>\")\n",
    "    text = re_sub(r\"\\b(\\S*?)(.)\\2{2,}\\b\", r\"\\1\\2 <elong>\")\n",
    "\n",
    "    ## -- I just don't understand why the Ruby script adds <allcaps> to everything so I limited the selection.\n",
    "    # text = re_sub(r\"([^a-z0-9()<>'`\\-]){2,}\", allcaps)\n",
    "    text = re_sub(r\"([A-Z]){2,}\", allcaps)\n",
    "    return text.lower()\n",
    "\n",
    "def read_texts(filename):\n",
    "    f = open(filename)\n",
    "    data = [line.strip() for line in f]\n",
    "    f.close()\n",
    "    return data\n",
    "\n",
    "texts_train = [tokenize(text) for text in read_texts(folder+\"texts_train.txt\")]\n",
    "#texts_test = [tokenize(text) for text in read_texts(folder+\"texts_test.txt\")]\n",
    "\n",
    "Z_train = np.loadtxt(folder+\"sent_train.txt\", dtype='int')\n",
    "#Z_test = np.loadtxt(folder+\"sent_test.txt\", dtype='int')\n",
    "\n",
    "print(\"Num. train texts: %d\" % len(texts_train))\n",
    "#print(\"Num. test texts:  %d\" % len(texts_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num. train texts: 14600\n",
      "Num. test texts:  80\n"
     ]
    }
   ],
   "source": [
    "##mask Z_train to be test....\n",
    "mask_gt = Z_train != -1\n",
    "\n",
    "texts_test = list(np.asarray(texts_train)[mask_gt])\n",
    "texts_train = list(np.asarray(texts_train)[~mask_gt])\n",
    "\n",
    "Z_test = Z_train[mask_gt]\n",
    "Z_train = Z_train[~mask_gt]\n",
    "\n",
    "print(\"Num. train texts: %d\" % len(texts_train))\n",
    "print(\"Num. test texts:  %d\" % len(texts_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## como tengo anotaciones en test podria utilizar para medir matrices de confusion \"fuera\" out of samplke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(Z_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10469 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "from keras import preprocessing\n",
    "MAX_NB_WORDS = 10000\n",
    "tokenizer = preprocessing.text.Tokenizer(num_words=MAX_NB_WORDS)\n",
    "tokenizer.fit_on_texts(texts_train+texts_test)\n",
    "sequences_train = tokenizer.texts_to_sequences(texts_train)\n",
    "sequences_test = tokenizer.texts_to_sequences(texts_test)\n",
    "MAX_NB_WORDS = len(tokenizer.word_index)\n",
    "print('Found %s unique tokens.' % len(tokenizer.word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real max:  50\n",
      "Shape of train tensor: (14600, 50)\n"
     ]
    }
   ],
   "source": [
    "lens = list(map(len,sequences_train))\n",
    "max_L = np.max(lens)\n",
    "print(\"Real max: \",max_L)\n",
    "\n",
    "X_train = preprocessing.sequence.pad_sequences(sequences_train, maxlen=max_L,dtype='int32', value=0,padding='pre')\n",
    "X_test = preprocessing.sequence.pad_sequences(sequences_test, maxlen=max_L,dtype='int32', value=0,padding='pre')\n",
    "print('Shape of train tensor:', X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing embedding matrix.\n",
      "Words found on glove:  9225\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_DIM = 100\n",
    "GLOVE_FILE = \"../AUX_DATA/glove.twitter.27B/glove.twitter.27B.%dd.txt\"%(EMBEDDING_DIM)\n",
    "\n",
    "embeddings_index = {}\n",
    "with open(GLOVE_FILE) as file:\n",
    "    for line in file:\n",
    "        values = line.split()\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[values[0]] = coefs\n",
    "print('Preparing embedding matrix.')\n",
    "sorted_x = sorted(tokenizer.word_counts.items(), key=lambda kv: kv[1], reverse=True)\n",
    "vocab = {value[0]:tokenizer.word_index[value[0]] for i, value in enumerate(sorted_x) if i < MAX_NB_WORDS}\n",
    "embedding_matrix = np.zeros((len(vocab)+1, EMBEDDING_DIM))\n",
    "v=0\n",
    "for word, i in vocab.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector # words not found in embedding index will be all-zeros.\n",
    "        v+=1\n",
    "del embeddings_index, sorted_x, tokenizer\n",
    "gc.collect()\n",
    "print(\"Words found on glove: \",v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load annotations / Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from code.representation import *\n",
    "from code.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading AMT data...\n",
      "Remove 109 annotators that do not annotate on this set \n",
      "Shape (data,annotators):  (14600, 394)\n",
      "Classes:  3\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading AMT data...\")\n",
    "y_obs = np.loadtxt(folder+\"answers.txt\", delimiter=' ', dtype='int16')\n",
    "\n",
    "#put mask\n",
    "y_obs = y_obs[~mask_gt]\n",
    "\n",
    "print(\"Remove %d annotators that do not annotate on this set \"%(np.sum(T_weights==0)))\n",
    "y_obs = y_obs[:,T_weights!=0]\n",
    "\n",
    "T_weights = np.sum(y_obs != -1,axis=0) #distribucion de anotaciones\n",
    "N,T = y_obs.shape\n",
    "Kl = np.max(y_obs)+1 # asumiendo que estan ordenadas\n",
    "print(\"Shape (data,annotators): \",(N,T))\n",
    "print(\"Classes: \",Kl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate conf matrix...\n",
    "confe_matrix_R = np.zeros((T,Kl,Kl),dtype=DTYPE_OP) #rodrigues add epsilon here\n",
    "for t in range(T):    \n",
    "    for i in range(N):\n",
    "        if y_obs[i,t] != -1:\n",
    "            confe_matrix_R[t,Z_train[i],y_obs[i,t]] +=1\n",
    "            \n",
    "    mask_nan = confe_matrix_R[t,:,:].sum(axis=-1) == 0\n",
    "    mean_replace = np.mean(confe_matrix_R[t,:,:][~mask_nan],axis=0)\n",
    "    for value in np.arange(Kl)[mask_nan]:\n",
    "        confe_matrix_R[t,value,:] =  1 #Rodrigues 1./K -- similar  to laplace smooth (prior 1)\n",
    "    confe_matrix_R[t,:,:] = confe_matrix_R[t,:,:]/confe_matrix_R[t,:,:].sum(axis=-1,keepdims=True) #normalize\n",
    "confe_matrix_R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum annotations in a example:  2\n",
      "Maximum annotations in a example:  248\n",
      "T data (expected value):  3.799931880108992\n",
      "Graphics of T weights\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum annotations by an annotator:  10\n",
      "Maximum annotations by an annotator:  452\n",
      "Mean annotations by an annotator:  110.90059642147118\n"
     ]
    }
   ],
   "source": [
    "#graphics and distribution? what is T_data\n",
    "N_ann = np.sum(y_obs != -1,axis=1) #distribucion de anotaciones con este valor\n",
    "\n",
    "sns.countplot(N_ann)\n",
    "plt.show()\n",
    "print(\"Minimum annotations in a example: \",N_ann.min())\n",
    "print(\"Maximum annotations in a example: \",N_ann.max())\n",
    "print(\"T data (expected value): \",N_ann.mean())\n",
    "\n",
    "print(\"Graphics of T weights\")\n",
    "plt.hist(T_weights)\n",
    "plt.show()\n",
    "\n",
    "plt.boxplot(T_weights)\n",
    "plt.show()\n",
    "print(\"Minimum annotations by an annotator: \",T_weights.min())\n",
    "print(\"Maximum annotations by an annotator: \",T_weights.max())\n",
    "print(\"Mean annotations by an annotator: \",T_weights.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delta Convergence criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from code.learning_models import LogisticRegression_Sklearn,LogisticRegression_Keras,MLP_Keras\n",
    "#deep learning\n",
    "from code.learning_models import default_CNN,default_RNN_text,default_CNN_text, Clonable_Model\n",
    "\n",
    "from code.utils import EarlyStopRelative\n",
    "ourCallback = EarlyStopRelative(monitor='loss',patience=1,min_delta=TOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upper Bound Model -- ideal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 50, 100)           1047000   \n",
      "_________________________________________________________________\n",
      "cu_dnngru_1 (CuDNNGRU)       (None, 50, 128)           88320     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50, 128)           0         \n",
      "_________________________________________________________________\n",
      "cu_dnngru_2 (CuDNNGRU)       (None, 64)                37248     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 1,172,763\n",
      "Trainable params: 125,763\n",
      "Non-trainable params: 1,047,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Z_train_onehot = keras.utils.to_categorical(Z_train)\n",
    "\n",
    "model_UB = default_RNN_text(max_L, Kl, embed_M=embedding_matrix)\n",
    "model_UB.compile(loss='categorical_crossentropy',optimizer=OPT)\n",
    "model_UB.summary()\n",
    "\n",
    "#hist = model_UB.fit(X_train,Z_train_onehot,epochs=EPOCHS_BASE,batch_size=BATCH_SIZE,verbose=0,callbacks=[ourCallback])\n",
    "#print(\"Trained IDeal Model, Epochs to converge =\",len(hist.epoch))\n",
    "clone_UB = Clonable_Model(model_UB)\n",
    "#Z_train_pred = model_UB.predict_classes(X_train)\n",
    "#Z_test_pred = model_UB.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Representation for MV in 0.487544 sec\n",
      "Representation for DS in 0.391745 sec\n",
      "Estimation MV in 0.001091 sec\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Z_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-e8c7bf6bc347>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mZ_train_onehot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mZ_test_onehot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'Z_test' is not defined"
     ]
    }
   ],
   "source": [
    "from code.baseline import LabelInference\n",
    "\n",
    "label_I = LabelInference(y_obs,TOL,type_inf = 'all')\n",
    "\n",
    "mv_probas, mv_conf_probas = label_I.mv_labels('probas')\n",
    "mv_onehot, mv_conf_onehot = label_I.mv_labels('onehot')\n",
    "\n",
    "Z_train_onehot = keras.utils.to_categorical(Z_train)\n",
    "Z_test_onehot = keras.utils.to_categorical(Z_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential,Model\n",
    "from keras.layers import *\n",
    "def default_CNN_text(input_dim,output_dim,embed_M=[]):\n",
    "    model = Sequential() \n",
    "    if len(embed_M) != 0:\n",
    "        T, R_t = embed_M.shape\n",
    "        emd_layer = Embedding(T, R_t,trainable=False,weights=[embed_M],input_length=input_dim)\n",
    "        model.add(emd_layer)\n",
    "    else:\n",
    "        model.add(InputLayer(input_shape=input_dim))\n",
    "    model.add(Conv1D(128, 3, activation='relu')) #kernel 5?\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling1D(2))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Conv1D(128, 3, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling1D(2))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(GlobalAveragePooling1D())\n",
    "    \n",
    "    #model.add(Flatten())\n",
    "    #model.add(Dense(32, activation='relu'))\n",
    "    #model.add(BatchNormalization())\n",
    "    #model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Dense(output_dim, activation='softmax')) \n",
    "    return model\n",
    "## muy parecida a la recurrente-.--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def default_RNN_text(input_dim,output_dim,embed_M=[]): \n",
    "    model = Sequential() \n",
    "    if len(embed_M) != 0:\n",
    "        T, R_t = embed_M.shape\n",
    "        emd_layer = Embedding(T, R_t,trainable=False,weights=[embed_M],input_length=input_dim)\n",
    "        model.add(emd_layer)\n",
    "    else:\n",
    "        model.add(InputLayer(input_shape=input_dim))\n",
    "    #model.add(Dropout(0.2))\n",
    "    \n",
    "    layer_gru1 = CuDNNGRU(128,return_sequences=True) #, dropout=0.2, recurrent_dropout=0.5)\n",
    "    #model.add(Bidirectional(layer_gru1)) \n",
    "    model.add(layer_gru1)\n",
    "    \n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    layer_gru2 = CuDNNGRU(64,return_sequences=False) #, dropout=0.2, recurrent_dropout=0.5)\n",
    "    #model.add(Bidirectional(layer_gru2)) #128 funciona con embd 100 (sin otra capa)\n",
    "    model.add(layer_gru2) #128 funciona con embd 100 (sin otra capa)\n",
    "    \n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    #model.add(Dense(32, activation='relu'))\n",
    "    #model.add(BatchNormalization())\n",
    "    #model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(output_dim, activation='softmax'))     \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 50, 100)           1046200   \n",
      "_________________________________________________________________\n",
      "cu_dnngru_1 (CuDNNGRU)       (None, 50, 128)           88320     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50, 128)           0         \n",
      "_________________________________________________________________\n",
      "cu_dnngru_2 (CuDNNGRU)       (None, 64)                37248     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 1,171,963\n",
      "Trainable params: 125,763\n",
      "Non-trainable params: 1,046,200\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_UB = default_RNN_text(max_L, Kl, embed_M=embedding_matrix)\n",
    "model_UB.compile(loss='categorical_crossentropy',optimizer=OPT, metrics=[\"accuracy\"])\n",
    "model_UB.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Z_train_onehot' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-c9c81e6a6548>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m hist=model_UB.fit(X_train,Z_train_onehot,epochs=EPOCHS_BASE,batch_size=BATCH_SIZE,verbose=2#,callbacks=[ourCallback]\n\u001b[0m\u001b[1;32m      2\u001b[0m                   ,validation_data=(X_test,Z_test_onehot))\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Trained IDeal Model, Epochs to converge =\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Z_train_onehot' is not defined"
     ]
    }
   ],
   "source": [
    "hist=model_UB.fit(X_train,Z_train_onehot,epochs=EPOCHS_BASE,batch_size=BATCH_SIZE,verbose=2#,callbacks=[ourCallback]\n",
    "                  ,validation_data=(X_test,Z_test_onehot))\n",
    "print(\"Trained IDeal Model, Epochs to converge =\",len(hist.epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(hist.history[\"loss\"],label=\"train\")\n",
    "plt.plot(hist.history[\"val_loss\"])\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Evaluation_metrics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-727d888a13fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mZ_test_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_UB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mevaluate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEvaluation_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_UB\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'keras'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mresults1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mZ_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mZ_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mZ_train_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mresults2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mZ_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mZ_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mZ_test_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Evaluation_metrics' is not defined"
     ]
    }
   ],
   "source": [
    "Z_train_pred = model_UB.predict_classes(X_train)\n",
    "Z_test_pred = model_UB.predict_classes(X_test)\n",
    "\n",
    "evaluate = Evaluation_metrics(model_UB,'keras',X_train.shape[0])\n",
    "results1 = evaluate.calculate_metrics(Z=Z_train,Z_pred=Z_train_pred)\n",
    "results2 = evaluate.calculate_metrics(Z=Z_test,Z_pred=Z_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Infer Labels (without predictive model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Representation for MV in 0.408480 sec\n",
      "Representation for DS in 0.243548 sec\n",
      "Estimation MV in 0.001065 sec\n",
      "Iter\tlog-likelihood\tdelta-CM\tdelta-ER\tdelta-LL\n",
      "1 \t -27183.041021216482\n",
      "2 \t -26683.63037059264 \t0.0036\t0.217832\t0.018372\n",
      "3 \t -26604.052262502795 \t0.0013\t0.153333\t0.002982\n",
      "4 \t -26581.120659392484 \t0.0009\t0.135273\t0.000862\n",
      "5 \t -26572.051021873947 \t0.0006\t0.116471\t0.000341\n",
      "6 \t -26567.66713283535 \t0.0004\t0.096018\t0.000165\n",
      "7 \t -26565.28705596884 \t0.0003\t0.076377\t0.000090\n",
      "8 \t -26563.915797805676 \t0.0002\t0.061133\t0.000052\n",
      "9 \t -26563.06980030351 \t0.0002\t0.049333\t0.000032\n",
      "10 \t -26562.491795676597 \t0.0001\t0.040711\t0.000022\n",
      "11 \t -26562.088037636953 \t0.0001\t0.033982\t0.000015\n",
      "12 \t -26561.77484054735 \t0.0001\t0.028485\t0.000012\n",
      "Class marginals\n",
      "[0.62 0.22 0.16]\n",
      "Estimation for DS in 46.763030 sec\n"
     ]
    }
   ],
   "source": [
    "from code.baseline import LabelInference\n",
    "\n",
    "label_I = LabelInference(y_obs,TOL,type_inf = 'all')\n",
    "\n",
    "mv_probas, mv_conf_probas = label_I.mv_labels('probas')\n",
    "mv_onehot, mv_conf_onehot = label_I.mv_labels('onehot')\n",
    "\n",
    "#confe_matrix_G = get_Global_confusionM(Z_train,label_I.y_obs_repeat)\n",
    "\n",
    "if y_obs.shape[1] <= 12000:\n",
    "    ds_labels,ds_conf = label_I.DS_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ACC MV on train:\",np.mean(mv_onehot.argmax(axis=1)==Z_train))\n",
    "print(\"ACC D&S on train:\",np.mean(ds_labels.argmax(axis=1)==Z_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model over soft-MV, Epochs to converge = 4\n"
     ]
    }
   ],
   "source": [
    "model_mvsoft = clone_UB.get_model()\n",
    "model_mvsoft.compile(loss='categorical_crossentropy',optimizer=OPT)\n",
    "hist=model_mvsoft.fit(X_train, mv_probas, epochs=EPOCHS_BASE,batch_size=BATCH_SIZE,verbose=0,callbacks=[ourCallback])\n",
    "print(\"Trained model over soft-MV, Epochs to converge =\",len(hist.epoch))\n",
    "Z_train_p  = model_mvsoft.predict(X_train)\n",
    "Z_train_pred = Z_train_p.argmax(axis=-1)\n",
    "Z_test_pred = model_mvsoft.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model over hard-MV, Epochs to converge = 4\n"
     ]
    }
   ],
   "source": [
    "model_mvhard = clone_UB.get_model()\n",
    "model_mvhard.compile(loss='categorical_crossentropy',optimizer=OPT)\n",
    "hist=model_mvhard.fit(X_train, mv_onehot, epochs=EPOCHS_BASE,batch_size=BATCH_SIZE,verbose=0,callbacks=[ourCallback])\n",
    "print(\"Trained model over hard-MV, Epochs to converge =\",len(hist.epoch))\n",
    "Z_train_p = model_mvhard.predict(X_train)\n",
    "Z_train_pred = Z_train_p.argmax(axis=-1)\n",
    "Z_test_pred = model_mvhard.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model over D&S, Epochs to converge = 4\n"
     ]
    }
   ],
   "source": [
    "model_ds = clone_UB.get_model()\n",
    "model_ds.compile(loss='categorical_crossentropy',optimizer=OPT)\n",
    "hist=model_ds.fit(X_train, ds_labels, epochs=EPOCHS_BASE,batch_size=BATCH_SIZE,verbose=0,callbacks=[ourCallback])\n",
    "print(\"Trained model over D&S, Epochs to converge =\",len(hist.epoch))\n",
    "Z_train_p = model_ds.predict(X_train)\n",
    "Z_train_pred = Z_train_p.argmax(axis=-1)\n",
    "Z_test_pred = model_ds.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raykar Model (joint predict model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (4999, 203, 2)\n"
     ]
    }
   ],
   "source": [
    "from code.baseline import RaykarMC\n",
    "y_obs_categorical = set_representation(y_obs,'onehot') #for raykar\n",
    "print(\"shape:\",y_obs_categorical.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raykarMC = RaykarMC(max_L, y_obs_categorical.shape[-1], T,epochs=1,optimizer=OPT,DTYPE_OP=DTYPE_OP)\n",
    "raykarMC.define_model(\"default rnn text\", embed=embedding_matrix)\n",
    "\n",
    "logL_hists,i_r = raykarMC.multiples_run(20,X_train,y_obs_categorical,batch_size=BATCH_SIZE,max_iter=EPOCHS_BASE,\n",
    "                                     tolerance=TOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_train_p = raykarMC.get_predictions(X_train)\n",
    "Z_train_pred =Z_train_p.argmax(axis=-1)\n",
    "Z_test_p = raykarMC.get_predictions(X_test)\n",
    "Z_test_pred = Z_test_p.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "for a, value in enumerate(logL_hists): #logL_hists\n",
    "    if a != i_r:\n",
    "        plt.plot(range(len(value)),value,'.-')\n",
    "plt.plot(range(len(logL_hists[i_r])),logL_hists[i_r],'o-',markersize=10,label=\"Selected run\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our Proposed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from code.MixtureofGroups import GroupMixtureGlo, GroupMixtureInd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vector of repeats:\n",
      " [[0 3 0]\n",
      " [1 1 1]\n",
      " [0 2 1]\n",
      " ...\n",
      " [0 3 0]\n",
      " [3 0 0]\n",
      " [1 2 0]]\n",
      "shape: (14600, 3)\n"
     ]
    }
   ],
   "source": [
    "\"\"\" AADIR A ARCHIVO GROUPS...\"\"\"\n",
    "def define_uniform_groups(power, r, M):\n",
    "    R_total = r.sum()\n",
    "    uniform_groups = np.asarray([power*R_total/M for _ in range(M)])\n",
    "    return uniform_groups\n",
    "\n",
    "#get our representation \n",
    "r_obs = set_representation(y_obs,\"repeat\")\n",
    "#confe_matrix_G = get_Global_confusionM(Z_train,r_obs)\n",
    "\n",
    "print(\"vector of repeats:\\n\",r_obs)\n",
    "print(\"shape:\",r_obs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is low entropy (information), maybe there is only a few groups in this dataset, the possible of different behavior is low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gMixture_Global = GroupMixtureGlo(max_L,Kl=r_obs.shape[1],M=5,epochs=0,optimizer=OPT,dtype_op=DTYPE_OP) \n",
    "\n",
    "gMixture_Global.define_model(\"default rnn text\", embed=embedding_matrix)\n",
    "\n",
    "logL_hists,i_r = gMixture_Global.multiples_run(1,X_train,r_obs,batch_size=BATCH_SIZE,max_iter=0,tolerance=TOL)\n",
    "\n",
    "aux = gMixture_Global.alpha_init.sum(axis=1).sum(axis=0)\n",
    "plt.bar(np.arange(gMixture_Global.M),aux)\n",
    "plt.show()\n",
    "gMixture_Global.get_alpha()\n",
    "plt.bar(np.arange(gMixture_Global.M),gMixture_Global.get_alpha())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select M based on JS on train and accuracy on val (as train has ground truth can evaluate JS)\n",
    "from code.evaluation import Evaluation_metrics\n",
    "logL_Mchange = []\n",
    "accTR_Mchange = []\n",
    "accTE_Mchange = []\n",
    "best_group_acc_Mchange = []\n",
    "probas_Mchange = []\n",
    "divergence1_Mchange = [] #JS Weighted\n",
    "divergence2_Mchange = [] #JS\n",
    "probGt_Mchange = []\n",
    "inertia_Mchange = [] \n",
    "\n",
    "uniform_groups = define_uniform_groups(0.1, r_obs, M_seted)\n",
    "uniform = True\n",
    "for M_seted in range(1,10+1):\n",
    "    for _ in range(10):\n",
    "        gMixture_Global = GroupMixtureGlo(max_L,Kl=r_obs.shape[1],M=M_seted,epochs=1,optimizer=OPT,dtype_op=DTYPE_OP) \n",
    "        gMixture_Global.define_model(\"default rnn text\", embed=embedding_matrix)\n",
    "        \n",
    "        if uniform:\n",
    "            #to uniform groups...\n",
    "            gMixture_Global.define_priors(\"laplace\")\n",
    "            gMixture_Global.define_priors(uniform_groups) \n",
    "        \n",
    "        logL_hists,i_r = gMixture_Global.multiples_run(20,Xstd_train,r_obs,batch_size=BATCH_SIZE,max_iter=EPOCHS_BASE,tolerance=TOL)\n",
    "        \n",
    "        print(\"Model with %d trained\"%(M_seted))\n",
    "        logL_Mchange.append(logL_hists[i_r])\n",
    "        probas_Mchange.append(gMixture_Global.get_alpha())\n",
    "\n",
    "        #measure metrics..\n",
    "        evaluate = Evaluation_metrics(gMixture_Global,'our1',plot=False) \n",
    "        aux = gMixture_Global.calculate_extra_components(Xstd_train,y_obs,T=T,calculate_pred_annotator=False)\n",
    "        predictions_m,prob_Gt,prob_Yzt,_ =  aux #to evaluate...\n",
    "        Z_train_pred = gMixture_Global.base_model.predict_classes(Xstd_train)\n",
    "        results1 = evaluate.calculate_metrics(Z=Z_train,Z_pred=Z_train_pred,conf_pred=prob_Yzt,conf_true=confe_matrix_R,y_o=y_obs)\n",
    "\n",
    "        accTR_Mchange.append(results1[0][\"Accuracy\"][0])\n",
    "        divergence1_Mchange.append(results1[0][\"Mean NormF\"][0])\n",
    "        divergence2_Mchange.append(results1[0][\"Mean JS\"][0])\n",
    "        probGt_Mchange.append(prob_Gt)\n",
    "\n",
    "        c_M = gMixture_Global.get_confusionM()\n",
    "        y_o_groups = gMixture_Global.get_predictions_groups(Xstd_val).argmax(axis=-1) #obtain p(y^o|x,g=m) and then argmax\n",
    "        Z_val_pred = gMixture_Global.base_model.predict_classes(Xstd_val)\n",
    "        results2 = evaluate.calculate_metrics(Z=Z_val,Z_pred=Z_val_pred,conf_pred=c_M, y_o_groups=y_o_groups)\n",
    "\n",
    "        best_group_acc_Mchange.append(np.max(results2[0][\"Accuracy\"]))\n",
    "        accTE_Mchange.append(results2[1][\"Accuracy\"][0])\n",
    "        inertia_Mchange.append(evaluate.inertia)\n",
    "        \n",
    "        del gMixture_Global,logL_hists,evaluate,predictions_m,prob_Gt,prob_Yzt,Z_train_pred,results1,results2,Z_val_pred\n",
    "        gc.collect()\n",
    "        keras.backend.clear_session()\n",
    "# cada 10 obtener promedio\n",
    "T_models = 9\n",
    "R = 10\n",
    "logL_Mchange = [np.mean( [value[-1] for value in logL_Mchange[i*R:(i+1)*R] ] ) for i in range(T_models)]\n",
    "accTR_Mchange = [np.mean(accTR_Mchange[i*R:(i+1)*R],axis=0) for i in range(T_models)]\n",
    "accTE_Mchange = [np.mean(accTE_Mchange[i*R:(i+1)*R],axis=0) for i in range(T_models)]\n",
    "best_group_acc_Mchange = [np.mean(best_group_acc_Mchange[i*R:(i+1)*R],axis=0) for i in range(T_models)]\n",
    "probas_Mchange = [np.mean(probas_Mchange[i*R:(i+1)*R],axis=0) for i in range(T_models)]\n",
    "divergence1_Mchange = [np.mean(divergence1_Mchange[i*R:(i+1)*R],axis=0) for i in range(T_models)] #KL or JS\n",
    "divergence2_Mchange = [np.mean(divergence2_Mchange[i*R:(i+1)*R],axis=0) for i in range(T_models)] #KL or JS\n",
    "probGt_Mchange = [np.mean(probGt_Mchange[i*R:(i+1)*R],axis=0) for i in range(T_models)]\n",
    "inertia_Mchange = [np.mean(inertia_Mchange[i*R:(i+1)*R],axis=0) for i in range(T_models)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_Mchange(logL_Mchange,\n",
    "         accTR_Mchange,\n",
    "         accTE_Mchange,\n",
    "         best_group_acc_Mchange,\n",
    "         probas_Mchange,\n",
    "         divergence1_Mchange,\n",
    "             divergence2_Mchange,\n",
    "         probGt_Mchange,\n",
    "         inertia_Mchange\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#T if i know T\n",
    "print(T)\n",
    "M_values = range(1,1+len(logL_Mchange))\n",
    "t = pd.DataFrame()\n",
    "t[\"#Groups\"] = M_values\n",
    "t[\">=1 annotator\"] = [ np.sum(probas*T >= 1) for probas in probas_Mchange]\n",
    "t[\">=2 annotator\"] = [ np.sum(probas*T >= 2) for probas in probas_Mchange] #si agrupa al menos tiene 2\n",
    "t[\"Used on annotators\"] = [ len(np.unique(prob_Gt.argmax(axis=1))) for prob_Gt in probGt_Mchange ]#based on p(g|t)\n",
    "t[\"Used on annotators limit >=0.01\"] = [ np.sum(prob_Gt.max(axis=0)>=0.01) for prob_Gt in probGt_Mchange ]#based on p(g|t)\n",
    "t[\"Used on annotators limit >=0.05\"] = [ np.sum(prob_Gt.max(axis=0)>=0.05) for prob_Gt in probGt_Mchange ]#based on p(g|t)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_seted = 3 #??\n",
    "\n",
    "uniform = False\n",
    "if uniform:\n",
    "    uniform_groups = define_uniform_groups(0.1, r_obs, M_seted)\n",
    "    print(uniform_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gMixture_Global = GroupMixtureGlo(max_L,Kl=r_obs.shape[1],M=M_seted,epochs=1,optimizer=OPT,dtype_op=DTYPE_OP) \n",
    "gMixture_Global.define_model(\"default rnn text\", embed=embedding_matrix)\n",
    "\n",
    "if uniform:\n",
    "    gMixture_Global.define_priors(\"laplace\")\n",
    "    gMixture_Global.define_priors(uniform_groups)\n",
    "\n",
    "logL_hists,i_r = gMixture_Global.multiples_run(20,X_train,r_obs,\n",
    "                                               batch_size=BATCH_SIZE,max_iter=EPOCHS_BASE,tolerance=TOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_train_p = gMixture_Global.get_predictions(X_train)\n",
    "Z_train_pred = Z_train_p.argmax(axis=-1)\n",
    "Z_test_p = gMixture_Global.get_predictions(X_test)\n",
    "Z_test_pred = Z_test_p.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "for a, value in enumerate(logL_hists): #logL_hists\n",
    "    if a != i_r:\n",
    "        plt.plot(range(len(value)),value,'.-')\n",
    "plt.plot(range(len(logL_hists[i_r])),logL_hists[i_r],'o-',markersize=10,label=\"Selected run\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of annotator representation (T, R_t)= (203, 203)\n"
     ]
    }
   ],
   "source": [
    "Y_ann_train, T_idx = set_representation(y_obs,\"onehotvar\")\n",
    "T_idx_unique = np.arange(T).reshape(-1,1)\n",
    "\n",
    "A = keras.utils.to_categorical(np.arange(T), num_classes=T) #fast way\n",
    "print(\"shape of annotator representation (T, R_t)=\", A.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from code.MixtureofGroups import *\n",
    "conf_mat, conf_mat_norm  = build_conf_Yvar(Y_ann_train, T_idx, r_obs.argmax(axis=-1))\n",
    "\n",
    "#A_rep = conf_mat_norm.reshape(conf_mat_norm.shape[0], Kl**2) #flatten\n",
    "A_rep = np.zeros((conf_mat.shape[0], Kl))\n",
    "for t in range(A_rep.shape[0]):\n",
    "    A_rep[t] = JS_confmatrixs(conf_mat_norm[t], np.identity(Kl),raw=True) #distancia a I (MV)\n",
    "    \n",
    "print(\"shape of annotator representation (T, R_t)=\", A_rep.shape)\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "model = PCA(2)\n",
    "aux_pca = model.fit_transform(A_rep)\n",
    "plt.scatter(aux_pca[:,0],aux_pca[:,1])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "A_rep = np.zeros((y_obs.shape[1], Kl))\n",
    "for i in range(N):\n",
    "    for l, t_idx in enumerate(T_idx[i]):\n",
    "        obs_t = Y_ann_train[i][l].argmax(axis=-1)\n",
    "        A_rep[t_idx, obs_t] += 1\n",
    "    \n",
    "from sklearn.decomposition import PCA\n",
    "model = PCA(2)\n",
    "aux_pca = model.fit_transform(A_rep)\n",
    "plt.scatter(aux_pca[:,0],aux_pca[:,1])\n",
    "plt.show()\n",
    "A_rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#different M_seted??\n",
    "M_seted = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gMixture_Ind1 = GroupMixtureInd(max_L,Kl=Kl,M=M_seted,epochs=1,optimizer=OPT,dtype_op=DTYPE_OP) \n",
    "gMixture_Ind1.define_model(\"default rnn text\", embed=embedding_matrix)\n",
    "\n",
    "#gMixture_Ind.define_model_group(\"mlp\", T, M_seted, 1, BatchN=True, embed=True, embed_M=A) #con o sin BN\n",
    "gMixture_Ind1.define_model_group(\"perceptron\", T, embed=True, embed_M=A, BatchN=True,bias=False)\n",
    "\n",
    "logL_hists,i_r = gMixture_Ind1.multiples_run(10,X_train,Y_ann_train, T_idx, A=[], batch_size=BATCH_SIZE,\n",
    "                                    pre_init_z=3,pre_init_g=0,max_iter=EPOCHS_BASE,tolerance=TOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_train_p = gMixture_Ind1.get_predictions_z(X_train)\n",
    "Z_train_pred = Z_train_p.argmax(axis=-1)\n",
    "Z_test_p = gMixture_Ind1.get_predictions_z(X_test)\n",
    "Z_test_pred = Z_test_p.argmax(axis=-1)\n",
    "prob_Gt = gMixture_Ind1.get_predictions_g(T_idx_unique) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gMixture_Ind3 = GroupMixtureInd(max_L,Kl=Kl,M=M_seted,epochs=1,optimizer=OPT,dtype_op=DTYPE_OP) \n",
    "gMixture_Ind3.define_model(\"default rnn text\", embed=embedding_matrix)\n",
    "\n",
    "gMixture_Ind3.define_model_group(\"mlp\", A_rep.shape[1], Kl*M_seted, 1, BatchN=False, embed=False) #con BN\n",
    "\n",
    "logL_hists,i_r = gMixture_Ind3.multiples_run(10,X_train,Y_ann_train, T_idx, A=A_rep, batch_size=BATCH_SIZE,\n",
    "                                   pre_init_z=3,pre_init_g=0,max_iter=EPOCHS_BASE,tolerance=TOL) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_train_p = gMixture_Ind3.get_predictions_z(X_train)\n",
    "Z_train_pred = Z_train_p.argmax(axis=-1)\n",
    "Z_test_p = gMixture_Ind3.get_predictions_z(X_test)\n",
    "Z_test_pred = Z_test_p.argmax(axis=-1)\n",
    "prob_Gt = gMixture_Ind3.get_predictions_g(A_rep) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "for a, value in enumerate(logL_hists): #logL_hists\n",
    "    if a != i_r:\n",
    "        plt.plot(range(len(value)),value,'.-')\n",
    "plt.plot(range(len(logL_hists[i_r])),logL_hists[i_r],'o-',markersize=10,label=\"Selected run\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import it:\n",
    "from code.evaluation import Evaluation_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate = Evaluation_metrics(model_UB,'keras',X_train.shape[0])\n",
    "print(\"*** Upper bound (Train with GT) ***\")\n",
    "\n",
    "print(\"Train\")\n",
    "results1 = evaluate.calculate_metrics(Z=Z_train,Z_pred=Z_train_pred)\n",
    "\n",
    "print(\"Test\")\n",
    "results2 = evaluate.calculate_metrics(Z=Z_test,Z_pred=Z_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Soft-Majority (Train with softMV) ***\n",
      "Train\n",
      "A result\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACC imiting Annot mean</th>\n",
       "      <th>Cross-entropy mean</th>\n",
       "      <th>ACC imiting Annot wmean</th>\n",
       "      <th>Cross entropy wmean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.7888</td>\n",
       "      <td>0.5506</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.5667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ACC imiting Annot mean  Cross-entropy mean  ACC imiting Annot wmean  \\\n",
       "0                  0.7888              0.5506                     0.78   \n",
       "\n",
       "   Cross entropy wmean  \n",
       "0               0.5667  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test\n",
      "A result\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 (micro)</th>\n",
       "      <th>F1 (macro)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>All</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.9059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Accuracy  F1 (micro)  F1 (macro)\n",
       "0  All      0.95        0.95      0.9059"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate = Evaluation_metrics(model_mvsoft,'keras',X_train.shape[0])\n",
    "evaluate.set_T_weights(T_weights)\n",
    "print(\"*** Soft-Majority (Train with softMV) ***\")\n",
    "\n",
    "print(\"Train\")\n",
    "#prob_Yzt = np.tile( mv_conf_probas, (T,1,1) )\n",
    "prob_Yx = np.tensordot(Z_train_p, mv_conf_probas,axes=[[1],[0]])\n",
    "prob_Yxt = np.tile(prob_Yx, (T,1,1)).transpose([1,0,2])\n",
    "\n",
    "#results1 = evaluate.calculate_metrics(conf_pred=prob_Yzt,yo_pred=prob_Yxt, conf_pred_G = mv_conf_probas)\n",
    "\n",
    "#immitate annotators\n",
    "results = evaluate.calculate_metrics(y_o=y_obs,yo_pred=prob_Yxt)\n",
    "\n",
    "print(\"Test\")\n",
    "results2 = evaluate.calculate_metrics(Z=Z_test,Z_pred=Z_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Hard-Majority (Train with hardMV) ***\n",
      "Train\n",
      "A result\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACC imiting Annot mean</th>\n",
       "      <th>Cross-entropy mean</th>\n",
       "      <th>ACC imiting Annot wmean</th>\n",
       "      <th>Cross entropy wmean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.7799</td>\n",
       "      <td>0.5652</td>\n",
       "      <td>0.7704</td>\n",
       "      <td>0.5839</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ACC imiting Annot mean  Cross-entropy mean  ACC imiting Annot wmean  \\\n",
       "0                  0.7799              0.5652                   0.7704   \n",
       "\n",
       "   Cross entropy wmean  \n",
       "0               0.5839  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test\n",
      "A result\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 (micro)</th>\n",
       "      <th>F1 (macro)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>All</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.8638</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Accuracy  F1 (micro)  F1 (macro)\n",
       "0  All     0.925       0.925      0.8638"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate = Evaluation_metrics(model_mvhard,'keras',X_train.shape[0])\n",
    "evaluate.set_T_weights(T_weights)\n",
    "print(\"*** Hard-Majority (Train with hardMV) ***\")\n",
    "\n",
    "print(\"Train\")\n",
    "prob_Yx = np.tensordot(Z_train_p, mv_conf_probas,axes=[[1],[0]])\n",
    "prob_Yxt = np.tile(prob_Yx, (T,1,1)).transpose([1,0,2])\n",
    "\n",
    "#results1 = evaluate.calculate_metrics(conf_pred=prob_Yzt,yo_pred=prob_Yxt, conf_pred_G = mv_conf_probas)\n",
    "\n",
    "#immitate annotators\n",
    "results = evaluate.calculate_metrics(y_o=y_obs,yo_pred=prob_Yxt)\n",
    "\n",
    "print(\"Test\")\n",
    "results2 = evaluate.calculate_metrics(Z=Z_test,Z_pred=Z_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Dawid and Skene model (Train with D&S) ***\n",
      "Train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fmena/Desktop/Dataset_Tesis/MixtureofGroups/code/evaluation.py:192: RuntimeWarning: divide by zero encountered in log\n",
      "  cross_entropy_loss = -np.mean(np.sum(keras.utils.to_categorical(t_annotations,num_classes=prob_data.shape[-1])*np.log(prob_data),axis=-1))\n",
      "/home/fmena/Desktop/Dataset_Tesis/MixtureofGroups/code/evaluation.py:192: RuntimeWarning: invalid value encountered in multiply\n",
      "  cross_entropy_loss = -np.mean(np.sum(keras.utils.to_categorical(t_annotations,num_classes=prob_data.shape[-1])*np.log(prob_data),axis=-1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A result\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACC imiting Annot mean</th>\n",
       "      <th>Cross-entropy mean</th>\n",
       "      <th>ACC imiting Annot wmean</th>\n",
       "      <th>Cross entropy wmean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.808</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.7967</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ACC imiting Annot mean  Cross-entropy mean  ACC imiting Annot wmean  \\\n",
       "0                   0.808                 NaN                   0.7967   \n",
       "\n",
       "   Cross entropy wmean  \n",
       "0                  NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test\n",
      "A result\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 (micro)</th>\n",
       "      <th>F1 (macro)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>All</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.9059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Accuracy  F1 (micro)  F1 (macro)\n",
       "0  All      0.95        0.95      0.9059"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate = Evaluation_metrics(model_ds,'keras',X_train.shape[0])\n",
    "evaluate.set_T_weights(T_weights)\n",
    "print(\"*** Dawid and Skene model (Train with D&S) ***\")\n",
    "\n",
    "print(\"Train\")\n",
    "#results1 = evaluate.calculate_metrics(Z=Z_train,Z_pred=Z_train_pred,conf_pred=ds_conf,conf_true=confe_matrix_R,\n",
    "#                                     conf_true_G =confe_matrix_G, conf_pred_G = ds_conf.mean(axis=0))\n",
    "prob_Yxt = np.tensordot(Z_train_p, ds_conf,axes=[[1],[1]])\n",
    "results = evaluate.calculate_metrics(y_o=y_obs,yo_pred=prob_Yxt)\n",
    "\n",
    "\n",
    "print(\"Test\")\n",
    "results2 = evaluate.calculate_metrics(Z=Z_test,Z_pred=Z_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate = Evaluation_metrics(raykarMC,'raykar')\n",
    "print(\"*** Raykar model multiples runs***\")\n",
    "\n",
    "print(\"Train\")\n",
    "prob_Yzt = raykarMC.get_confusionM()\n",
    "prob_Yxt = raykarMC.get_predictions_annot(X_train,data=Z_train_p)\n",
    "results = evaluate.calculate_metrics(Z=Z_train,Z_pred=Z_train_pred,conf_pred=prob_Yzt,conf_true=confe_matrix_R,\n",
    "                                     y_o=y_obs,yo_pred=prob_Yxt,conf_true_G =confe_matrix_G, conf_pred_G = prob_Yzt.mean(axis=0))\n",
    "\n",
    "results = evaluate.calculate_metrics(y_o=y_obs,yo_pred=prob_Yxt)\n",
    "\n",
    "print(\"Test\")\n",
    "results2 = evaluate.calculate_metrics(Z=Z_test,Z_pred=Z_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate = Evaluation_metrics(gMixture_Global,'our1') \n",
    "aux = gMixture_Global.calculate_extra_components(X_train,y_obs,T=T,calculate_pred_annotator=True,p_z=Z_train_p)\n",
    "predictions_m,prob_Gt,prob_Yzt,prob_Yxt =  aux #to evaluate...\n",
    "prob_Yz = gMixture_Global.calculate_Yz()\n",
    "evaluate.set_Gt(prob_Gt)\n",
    "print(\"*** Ours Global multiples runs***\") #lambda = random\n",
    "\n",
    "print(\"Train\")\n",
    "y_o_groups = predictions_m.argmax(axis=-1)\n",
    "results = evaluate.calculate_metrics(Z=Z_train,Z_pred=Z_train_pred,conf_pred=prob_Yzt,conf_true=confe_matrix_R,\n",
    "                                     y_o=y_obs,yo_pred=prob_Yxt, y_o_groups=y_o_groups,\n",
    "                                    conf_true_G =confe_matrix_G, conf_pred_G = prob_Yz)\n",
    "\n",
    "results = evaluate.calculate_metrics(y_o=y_obs,yo_pred=prob_Yxt)\n",
    "\n",
    "print(\"Test\")\n",
    "c_M = gMixture_Global.get_confusionM()\n",
    "y_o_groups = gMixture_Global.get_predictions_groups(X_test,data=Z_test_p).argmax(axis=-1) #obtain p(y^o|x,g=m) and then argmax\n",
    "results = evaluate.calculate_metrics(Z=Z_test,Z_pred=Z_test_pred,conf_pred=c_M, y_o_groups=y_o_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate = Evaluation_metrics(gMixture_Global,'our1') \n",
    "aux = gMixture_Global.calculate_extra_components(X_train,y_obs,T=T,calculate_pred_annotator=True,p_z=Z_train_p)\n",
    "predictions_m,prob_Gt,prob_Yzt,prob_Yxt =  aux #to evaluate...\n",
    "evaluate.set_Gt(prob_Gt)\n",
    "print(\"*** Ours Global multiples runs (Uniform priors) ***\") #groups uniform...\n",
    "\n",
    "print(\"Train\")\n",
    "y_o_groups = predictions_m.argmax(axis=-1)\n",
    "results = evaluate.calculate_metrics(Z=Z_train,Z_pred=Z_train_pred,conf_pred=prob_Yzt,conf_true=confe_matrix_R,y_o=y_obs,yo_pred=prob_Yxt, y_o_groups=y_o_groups)\n",
    "\n",
    "results = evaluate.calculate_metrics(y_o=y_obs,yo_pred=prob_Yxt)\n",
    "\n",
    "print(\"Test\")\n",
    "c_M = gMixture_Global.get_confusionM()\n",
    "y_o_groups = gMixture_Global.get_predictions_groups(X_test,data=Z_test_p).argmax(axis=-1) #obtain p(y^o|x,g=m) and then argmax\n",
    "results = evaluate.calculate_metrics(Z=Z_test,Z_pred=Z_test_pred,conf_pred=c_M, y_o_groups=y_o_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate = Evaluation_metrics(gMixture_Ind1,'our1') \n",
    "aux = gMixture_Ind1.calculate_extra_components(X_train, A,calculate_pred_annotator=True,p_z=Z_train_p,p_g=prob_Gt)\n",
    "predictions_m,prob_Gt,prob_Yzt,prob_Yxt =  aux #to evaluate...\n",
    "prob_Yz = gMixture_Ind1.calculate_Yz(prob_Gt)\n",
    "evaluate.set_Gt(prob_Gt)\n",
    "print(\"*** Ours Individual-T multiples runs***\")\n",
    "\n",
    "print(\"Train\")\n",
    "y_o_groups = predictions_m.argmax(axis=-1)\n",
    "results = evaluate.calculate_metrics(Z=Z_train,Z_pred=Z_train_pred,conf_pred=prob_Yzt,conf_true=confe_matrix_R,\n",
    "                                     y_o=y_obs,yo_pred=prob_Yxt, y_o_groups=y_o_groups,\n",
    "                                    conf_true_G =confe_matrix_G, conf_pred_G = prob_Yz)\n",
    "results = evaluate.calculate_metrics(y_o=y_obs,yo_pred=prob_Yxt)\n",
    "\n",
    "print(\"Test\")\n",
    "c_M = gMixture_Ind1.get_confusionM()\n",
    "y_o_groups = gMixture_Ind1.get_predictions_groups(X_test,data=Z_test_p).argmax(axis=-1) #obtain p(y^o|x,g=m) and then argmax\n",
    "results = evaluate.calculate_metrics(Z=Z_test,Z_pred=Z_test_pred,conf_pred=c_M, y_o_groups=y_o_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate = Evaluation_metrics(gMixture_Ind3,'our1') \n",
    "aux = gMixture_Ind3.calculate_extra_components(X_train, A,calculate_pred_annotator=True,p_z=Z_train_p,p_g=prob_Gt)\n",
    "predictions_m,prob_Gt,prob_Yzt,prob_Yxt =  aux #to evaluate...\n",
    "prob_Yz = gMixture_Ind3.calculate_Yz(prob_Gt)\n",
    "evaluate.set_Gt(prob_Gt)\n",
    "print(\"*** Ours Individual-K multiples runs***\")\n",
    "\n",
    "print(\"Train\")\n",
    "y_o_groups = predictions_m.argmax(axis=-1)\n",
    "results = evaluate.calculate_metrics(Z=Z_train,Z_pred=Z_train_pred,conf_pred=prob_Yzt,conf_true=confe_matrix_R,\n",
    "                                     y_o=y_obs,yo_pred=prob_Yxt, y_o_groups=y_o_groups,\n",
    "                                    conf_true_G =confe_matrix_G, conf_pred_G = prob_Yz)\n",
    "results = evaluate.calculate_metrics(y_o=y_obs,yo_pred=prob_Yxt)\n",
    "\n",
    "print(\"Test\")\n",
    "c_M = gMixture_Ind3.get_confusionM()\n",
    "y_o_groups = gMixture_Ind3.get_predictions_groups(X_test,data=Z_test_p).argmax(axis=-1) #obtain p(y^o|x,g=m) and then argmax\n",
    "results = evaluate.calculate_metrics(Z=Z_test,Z_pred=Z_test_pred,conf_pred=c_M, y_o_groups=y_o_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### project confusion matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_conf(m):\n",
    "    return m.reshape(m.shape[0], np.prod(m.shape[1:]))\n",
    "\n",
    "to_plot = flatten_conf(confe_matrix_R)\n",
    "\n",
    "centroids_plot_G = flatten_conf(gMixture_Global.get_confusionM())\n",
    "centroids_plot_I2 = flatten_conf(gMixture_Ind2.get_confusionM())\n",
    "centroids_plot_I3 = flatten_conf(gMixture_Ind3.get_confusionM())\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "model = PCA(2)\n",
    "\n",
    "to_plot = model.fit_transform(to_plot)\n",
    "centroids_plot_G = model.transform(centroids_plot_G)\n",
    "centroids_plot_I2 = model.transform(centroids_plot_I2)\n",
    "centroids_plot_I3 = model.transform(centroids_plot_I3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "plt.scatter(to_plot[:,0], to_plot[:,1], label=\"Annotators\")\n",
    "plt.scatter(centroids_plot_G[:,0], centroids_plot_G[:,1], s=150,marker=\"*\", color='g',label=\"Centroids Global\")\n",
    "plt.scatter(centroids_plot_I2[:,0], centroids_plot_I2[:,1],s=150, marker=\"X\", color='magenta',label=\"Centroids Individual 2\")\n",
    "plt.scatter(centroids_plot_I3[:,0], centroids_plot_I3[:,1], s=150, marker=\"X\", color='hotpink',label=\"Centroids Individual 3\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##plotear probabilidades de matriz  de conf.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3]",
   "language": "python",
   "name": "conda-env-py3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
